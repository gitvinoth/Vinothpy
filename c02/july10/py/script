
from typing import Dict, Any
import logging
from pyspark.sql import DataFrame
from pyspark.sql import functions as F
from pyspark.sql.window import Window

def __main(spark_df: DataFrame, current_time_range: Dict[str, int], rule: Dict[str, Any]):
    logger = logging.getLogger("ZScoreRule")
    logger.setLevel(logging.INFO)
    handler = logging.StreamHandler()
    formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
    handler.setFormatter(formatter)
    if not logger.hasHandlers():
        logger.addHandler(handler)

    logger.info("Starting Z-Score anomaly detection")

    start_time = current_time_range["start_time"]
    end_time = current_time_range["end_time"]
    duration = rule.get("metadata", {}).get("duration", 3600)
    threshold = rule.get("threshold", 10)

    logger.info(f"Z-Score Rule Triggered. start_time={start_time}, end_time={end_time}, duration={duration}, threshold={threshold}")

    full_range_start = start_time - duration
    df = spark_df.filter(
        (F.col("epoch_timestamp") >= full_range_start) & (F.col("epoch_timestamp") < end_time)
    ).select("epoch_timestamp", "pressure")

    logger.info("Performing rolling mean and stddev calculations")
    w = Window.orderBy("epoch_timestamp").rangeBetween(-duration, -1)
    df_with_stats = df.withColumn("mean", F.mean("pressure").over(w)) \
                      .withColumn("stddev", F.stddev("pressure").over(w)) \
                      .withColumn("z_score", (F.col("pressure") - F.col("mean")) / F.col("stddev")) \
                      .withColumn("Alert_Triggered", F.abs(F.col("z_score")) > threshold) \
                      .filter((F.col("epoch_timestamp") >= start_time) & (F.col("epoch_timestamp") < end_time))

    anomalies_df = df_with_stats.filter(F.col("Alert_Triggered") == True)
    anomalies = anomalies_df.select("epoch_timestamp", "pressure").rdd.map(lambda row: row.asDict()).collect()

    if anomalies:
        graph = {
            "type": "line-chart",
            "xaxis": {
                "label": "timestamp",
                "data": [a["epoch_timestamp"] for a in anomalies]
            },
            "yaxis": {
                "label": "Pressure",
                "data": [a["pressure"] for a in anomalies]
            }
        }
        anomaly_output = [{
            "start_time": start_time,
            "end_time": end_time,
            "graphs": [graph]
        }]
        logger.info("Anomalies detected, calling create_anomaly")
        create_anomaly(anomaly_output, rule)
    else:
        logger.info("No anomalies detected")

def create_anomaly(anomalies, rule: Dict[str, Any]):
    logger = logging.getLogger("ZScoreRule")
    logger.info("Sending anomalies to the sink")
    print("Anomalies Sent:", anomalies)
    logger.info("Anomalies sent successfully")
